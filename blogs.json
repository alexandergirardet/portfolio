{"status":"ok","feed":{"url":"https://medium.com/feed/@alexgirardet","title":"Stories by Alexgirardet on Medium","link":"https://medium.com/@alexgirardet?source=rss-c365d560a735------2","author":"","description":"Stories by Alexgirardet on Medium","image":"https://cdn-images-1.medium.com/fit/c/150/150/0*fYF2q8z_PA1BvYhJ.jpg"},"items":[{"title":"Analysing my Second Brain","pubDate":"2024-02-22 12:52:01","link":"https://medium.com/@alexgirardet/analysing-my-second-brain-b4f8e5cc8caf?source=rss-c365d560a735------2","guid":"https://medium.com/p/b4f8e5cc8caf","author":"Alexgirardet","thumbnail":"","description":"\n<p>Leveraging Descriptive and Predictive Analytics in becoming data-driven.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zKinXzdshjQfks210ZcbuQ.jpeg\"></figure><p>My previous blog post touched on the ability of individuals to become data-driven. If you have not seen it yet, I suggest checking it out to understand how this data came to be, and the motivation behind\u00a0this.</p>\n<p>In part 2 of this series, I will be exploring how to leverage descriptive analytics, consisting of summarising past data to understand what has happened, as well as predictive analytics to predict future outcomes based on historical data.</p>\n<p>These findings will be primarily generated from two data sources, and utilise NLP models to extract insights.</p>\n<ul>\n<li>My daily standup\u00a0journals</li>\n<li>My Kindle Reading Highlights</li>\n</ul>\n<h3>Daily Standup</h3>\n<p>One of the concepts that my system has taken from the agile methodology and scrum framework is the concept of daily standup. During this, I aim to talk through my progress towards my goals, personal blockers and general life pains I am facing at the moment. This is a habit that I picked up 18 months ago and have followed through with relatively well.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/531/1*hL6D74JRhbTtcwotA3FAOA.png\"><figcaption>Daily standup on\u00a0Notion</figcaption></figure><p>Utilising Notion\u2019s API, I have set up a data pipeline from which I export my notes to a hosted MongoDB server, allowing me to quickly index and access my notes programmatically for analysis. This database serves as the basis for this upcoming analysis, and all code is available on\u00a0GitHub.</p>\n<h4>Frequency of\u00a0Habit</h4>\n<p>A form of Descriptive analytics is being able to visualize patterns over time. Visualizing the frequency of my daily standup habit I can identify\u00a0trends.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*-3HCFoJZeaC8pwdPpu7x3Q.png\"><figcaption>Frequency of my daily standup habit, measured by the number of words written each\u00a0day</figcaption></figure><p>Immediately it is clear that Sunday seems to be a day in which I am much less likely to journal. There also seems to be a seasonable component in which summer months have a lower frequency of daily standups.</p>\n<h3>NLP Analysis</h3>\n<p>As the daily standup note consists of Natural language I can leverage open-source NLP models to extract further insights into the types of topics I am discussing and how those may change over time. Additionally, I can also visualize how my emotions or feelings have changed due to particular events or seasonal changes. Allowing me to assess the impact of events on my\u00a0life.</p>\n<h4>Topic Modeling</h4>\n<p>Using the <strong>ml6team/keyphrase-extraction-kbir-inspec</strong> key extraction model, we can extract relevant topics from text, and give an indication as to which topics I have been most interested in, and how that has changed over\u00a0time.</p>\n<pre>from transformers import (<br>    TokenClassificationPipeline,<br>    AutoModelForTokenClassification,<br>    AutoTokenizer,<br>)<br>from transformers.pipelines import AggregationStrategy<br>import numpy as np<br><br>class KeyphraseExtractionPipeline(TokenClassificationPipeline):<br>    def __init__(self, model, *args, **kwargs):<br>        super().__init__(<br>            model=AutoModelForTokenClassification.from_pretrained(model),<br>            tokenizer=AutoTokenizer.from_pretrained(model),<br>            *args,<br>            **kwargs<br>        )<br><br>    def postprocess(self, all_outputs):<br>        results = super().postprocess(<br>            all_outputs=all_outputs,<br>            aggregation_strategy=AggregationStrategy.SIMPLE,<br>        )<br>        return np.unique([result.get(\"word\").strip() for result in results])<br><br># Load pipeline<br>model_name = \"ml6team/keyphrase-extraction-kbir-inspec\"<br>extractor = KeyphraseExtractionPipeline(model=model_name)<br>df['keyphrases'] = df['text'].apply(lambda x: extractor(x))</pre>\n<p>This results in a list of topics that have been extracted from my standups. A word cloud visualizes which topics I have mentioned the most over the last 18\u00a0months.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*48A48GKbpVN8FdQbEogdHA.png\"><figcaption>Word cloud of topics mentioned</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*0mJdR5RoS5mh1wki87PgDQ.png\"><figcaption>Frequency of Key\u00a0Phrases</figcaption></figure><p>Data Engineering, the current company I work for, MLops and other topics have dominated my interest as I aim to grapple with learning these concepts.</p>\n<p>A particularly interesting insight would be to see how my interests have changed over\u00a0time.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*AtBKpROKZBG7D08uAJFkXA.png\"><figcaption>Change of interests over\u00a0time</figcaption></figure><p>This generally reflects my interests quite well, particularly my recent interest in learning\u00a0MLOps.</p>\n<h3>Emotional modeling</h3>\n<p>Emotions can represent your state of mind and well-being over the last year. While this is rather personal I will be happy to share for the sake of transparency and learning. Utilising the <strong>SamLowe/roberta-base-go_emotions</strong> open-source model we can generate continuous values representing the intensity over 26 emotions being displayed in the input\u00a0text.</p>\n<pre>from transformers import pipeline, RobertaTokenizer<br>import pandas as pd<br>import numpy as np<br><br># Initialize the tokenizer and classifier<br>model_name = \"SamLowe/roberta-base-go_emotions\"<br>tokenizer = RobertaTokenizer.from_pretrained(model_name)<br>classifier = pipeline(task=\"text-classification\", model=model_name)</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*ded-zkV0HmblsILtbvYAUA.png\"><figcaption>The most frequent emotions expressed in my daily\u00a0standups</figcaption></figure><p>Again the time-based nature of my journals enables me to visualize my mental state over several months. By creating a Smooth Moving Average I can identify peaks and troughs which may identify the impact of seasons on my mood or of one-off\u00a0events.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*6iv-tRxZz7FjWGGzQndF5g.png\"></figure><p>There are a few interesting insights reflected in this visualization. Firstly the seasonal impact of winter on my mood is pretty clearly shown as Joy went through several spikes over the summer and had a long trough over the winter months. This may lead me to make changes to my winter routine in the next year. A peak of New Year\u2019s optimism is also interesting as I laid out plans for the upcoming year. It is also quite interesting to identify that sadness and joy are emotions that are extremely volatile and come through peaks that quickly drop\u00a0off.</p>\n<h3>Reading</h3>\n<p>A primary goal of mine in the last few years has been to make it a habit of reading. I would like to dive into my reading habits, understand where I am currently falling short, and what actions I could take to improve this habit. A major value of digitising your inputs is that certain apps will track your behaviour and allow you to export that data. Amazon Kindle insights track your reading habits over time. This section will introduce predictive analytics, and how we can use the synergistic effects of our data to drive future behavior.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*aO8jV3FWeHPdqlLiwlkwig.png\"><figcaption>Visualization of my reading\u00a0habits</figcaption></figure><p>Once again a seasonal pattern seems to be at foot in which I am less likely to stick to my habits over the summer months, as I may be prioritizing fun, and outdoor activities (As you\u00a0should).</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*f1ap-hquX-cDWb63pT50yw.png\"><figcaption>A 30-day moving average of days\u00a0read</figcaption></figure><p>By taking a proportion of days read in the last 30 days, this seasonal pattern can be better identified. This is a very good example of exposing a behavioural pattern of\u00a0mine.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*VgkgNiku5kPqFFgvyotvQQ.png\"><figcaption>Daily Reading\u00a0habits</figcaption></figure><p>Additionally, we can see that on Fridays, Saturdays and Sundays I would be much less likely to read. This implies that to increase my frequency of reading I should focus on finding a 20-minute slot over the weekends to read, leading to the highest return in improving this\u00a0habit.</p>\n<h4>Impact of journaling on reading\u00a0habit</h4>\n<p>This is the first example of how storing two disparate datasets embodies network effects, as my reading habits and journaling habits can be leveraged together to identify behavioural patterns not visible through analysis in isolation.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*tpa-8KE_--Yf5vH3lU_Hyg.png\"><figcaption>Reading habits and journaling</figcaption></figure><p>Days in which I journaled have a much higher likelihood of me reading. Journaling is usually the first thing I do when I wake up and implies there is a pattern of habit continuity in that I am more likely to follow through with other habits if I perform the first one of the\u00a0day.</p>\n<h4>Predicting my likelihood of\u00a0reading</h4>\n<p>Let\u2019s take this a step further, and try and predict the probability that I will read in a given day based on historical trends in the data. This introduces us to the concept of predictive analytics and determining my future behaviour based on other\u00a0habits.</p>\n<p>One hot encoding the months and days of the week, as well as adding a binary feature journaled (True, if I journaled that day) and the lagged moving average of the proportion of days reading in the last 2 weeks. I can perform a simple regression analysis, determining the impact of previous behaviours and seasonal/weekly trends.</p>\n<p>My training set consists of the first 408 days between October 1st 2022 and November 11th 2023. My test set consists of 100 days from November 11th up until the 2nd of February\u00a02024.</p>\n<pre>              precision    recall  f1-score   support<br><br>         0.0       0.57      0.27      0.36        15<br>         1.0       0.88      0.96      0.92        85<br><br>    accuracy                           0.86       100<br>   macro avg       0.73      0.62      0.64       100<br>weighted avg       0.84      0.86      0.84       100<br><br>journalled: 1.1440068424395116<br>month_1: 0.16044342220670138<br>month_2: 0.3323670002244325<br>month_3: 0.7024553142987882<br>month_4: 0.22966851950692688<br>month_5: -0.8973105152837405<br>month_6: -0.30571280967693937<br>month_7: -0.26748064587381354<br>month_8: -0.3400904017551615<br>month_9: -0.47128785358425396<br>month_10: 1.1122827221321216<br>month_11: -0.11306428172788532<br>month_12: -0.1512587216823901<br>day_0: 0.21844147183274587<br>day_1: 0.5648366645343597<br>day_2: 0.40001927074086285<br>day_3: 0.5277073233344185<br>day_4: -0.5166125876634535<br>day_5: -1.2279971272203802<br>day_6: 0.0246167332262347<br>lagged_moving_average: 1.2349710812455899<br>Prediction for the last day (Feb 21, 2024): Read</pre>\n<p>The model excels at predicting the day when I will read, with a precision of 88%. However, predicting days I will not read is less evident with a much weaker precision of\u00a057%.</p>\n<p><strong>Findings</strong></p>\n<ul>\n<li>Journaling is clearly shown to increase my likelihood of reading, as indicated by a positive coefficient of\u00a01.144</li>\n<li>A seasonal trend is identified as summer months negatively impact the probability of\u00a0reading</li>\n<li>A weekly trend is also identified with negative coefficients for Fridays and Saturdays</li>\n<li>Consistency of behaviour is identified as I am more likely to read in a given day if I have been reading a lot in the last 2\u00a0weeks</li>\n</ul>\n<p><strong>Predicting future behaviour</strong></p>\n<p>The model predicts that on Wednesday, February 21st 2024, a day in which I journaled my lagged 14-day moving average of the proportion of days read is 0.93%. I have a 92.5% probability of reading that\u00a0day.</p>\n<h3>Prescriptive Analytics</h3>\n<p>Finally, onto the holy grail of analytics. Prescriptive analytics. Imagine a system in which you can capture and automate routine processes. Have a specialist trained on your data and suggest to you actions to take based on your previous behaviour or concerns you have addressed. Or simply a system that can explain to you any concept you have ever faced in your own words. Well, that is the subject of part three of this blog, which dives into how to use the RAG architecture and GPT agents to leverage your data in scaling your abilities and reduce the burden of administrative work in your day-to-day life.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b4f8e5cc8caf\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>Leveraging Descriptive and Predictive Analytics in becoming data-driven.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zKinXzdshjQfks210ZcbuQ.jpeg\"></figure><p>My previous blog post touched on the ability of individuals to become data-driven. If you have not seen it yet, I suggest checking it out to understand how this data came to be, and the motivation behind\u00a0this.</p>\n<p>In part 2 of this series, I will be exploring how to leverage descriptive analytics, consisting of summarising past data to understand what has happened, as well as predictive analytics to predict future outcomes based on historical data.</p>\n<p>These findings will be primarily generated from two data sources, and utilise NLP models to extract insights.</p>\n<ul>\n<li>My daily standup\u00a0journals</li>\n<li>My Kindle Reading Highlights</li>\n</ul>\n<h3>Daily Standup</h3>\n<p>One of the concepts that my system has taken from the agile methodology and scrum framework is the concept of daily standup. During this, I aim to talk through my progress towards my goals, personal blockers and general life pains I am facing at the moment. This is a habit that I picked up 18 months ago and have followed through with relatively well.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/531/1*hL6D74JRhbTtcwotA3FAOA.png\"><figcaption>Daily standup on\u00a0Notion</figcaption></figure><p>Utilising Notion\u2019s API, I have set up a data pipeline from which I export my notes to a hosted MongoDB server, allowing me to quickly index and access my notes programmatically for analysis. This database serves as the basis for this upcoming analysis, and all code is available on\u00a0GitHub.</p>\n<h4>Frequency of\u00a0Habit</h4>\n<p>A form of Descriptive analytics is being able to visualize patterns over time. Visualizing the frequency of my daily standup habit I can identify\u00a0trends.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*-3HCFoJZeaC8pwdPpu7x3Q.png\"><figcaption>Frequency of my daily standup habit, measured by the number of words written each\u00a0day</figcaption></figure><p>Immediately it is clear that Sunday seems to be a day in which I am much less likely to journal. There also seems to be a seasonable component in which summer months have a lower frequency of daily standups.</p>\n<h3>NLP Analysis</h3>\n<p>As the daily standup note consists of Natural language I can leverage open-source NLP models to extract further insights into the types of topics I am discussing and how those may change over time. Additionally, I can also visualize how my emotions or feelings have changed due to particular events or seasonal changes. Allowing me to assess the impact of events on my\u00a0life.</p>\n<h4>Topic Modeling</h4>\n<p>Using the <strong>ml6team/keyphrase-extraction-kbir-inspec</strong> key extraction model, we can extract relevant topics from text, and give an indication as to which topics I have been most interested in, and how that has changed over\u00a0time.</p>\n<pre>from transformers import (<br>    TokenClassificationPipeline,<br>    AutoModelForTokenClassification,<br>    AutoTokenizer,<br>)<br>from transformers.pipelines import AggregationStrategy<br>import numpy as np<br><br>class KeyphraseExtractionPipeline(TokenClassificationPipeline):<br>    def __init__(self, model, *args, **kwargs):<br>        super().__init__(<br>            model=AutoModelForTokenClassification.from_pretrained(model),<br>            tokenizer=AutoTokenizer.from_pretrained(model),<br>            *args,<br>            **kwargs<br>        )<br><br>    def postprocess(self, all_outputs):<br>        results = super().postprocess(<br>            all_outputs=all_outputs,<br>            aggregation_strategy=AggregationStrategy.SIMPLE,<br>        )<br>        return np.unique([result.get(\"word\").strip() for result in results])<br><br># Load pipeline<br>model_name = \"ml6team/keyphrase-extraction-kbir-inspec\"<br>extractor = KeyphraseExtractionPipeline(model=model_name)<br>df['keyphrases'] = df['text'].apply(lambda x: extractor(x))</pre>\n<p>This results in a list of topics that have been extracted from my standups. A word cloud visualizes which topics I have mentioned the most over the last 18\u00a0months.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*48A48GKbpVN8FdQbEogdHA.png\"><figcaption>Word cloud of topics mentioned</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*0mJdR5RoS5mh1wki87PgDQ.png\"><figcaption>Frequency of Key\u00a0Phrases</figcaption></figure><p>Data Engineering, the current company I work for, MLops and other topics have dominated my interest as I aim to grapple with learning these concepts.</p>\n<p>A particularly interesting insight would be to see how my interests have changed over\u00a0time.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*AtBKpROKZBG7D08uAJFkXA.png\"><figcaption>Change of interests over\u00a0time</figcaption></figure><p>This generally reflects my interests quite well, particularly my recent interest in learning\u00a0MLOps.</p>\n<h3>Emotional modeling</h3>\n<p>Emotions can represent your state of mind and well-being over the last year. While this is rather personal I will be happy to share for the sake of transparency and learning. Utilising the <strong>SamLowe/roberta-base-go_emotions</strong> open-source model we can generate continuous values representing the intensity over 26 emotions being displayed in the input\u00a0text.</p>\n<pre>from transformers import pipeline, RobertaTokenizer<br>import pandas as pd<br>import numpy as np<br><br># Initialize the tokenizer and classifier<br>model_name = \"SamLowe/roberta-base-go_emotions\"<br>tokenizer = RobertaTokenizer.from_pretrained(model_name)<br>classifier = pipeline(task=\"text-classification\", model=model_name)</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*ded-zkV0HmblsILtbvYAUA.png\"><figcaption>The most frequent emotions expressed in my daily\u00a0standups</figcaption></figure><p>Again the time-based nature of my journals enables me to visualize my mental state over several months. By creating a Smooth Moving Average I can identify peaks and troughs which may identify the impact of seasons on my mood or of one-off\u00a0events.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*6iv-tRxZz7FjWGGzQndF5g.png\"></figure><p>There are a few interesting insights reflected in this visualization. Firstly the seasonal impact of winter on my mood is pretty clearly shown as Joy went through several spikes over the summer and had a long trough over the winter months. This may lead me to make changes to my winter routine in the next year. A peak of New Year\u2019s optimism is also interesting as I laid out plans for the upcoming year. It is also quite interesting to identify that sadness and joy are emotions that are extremely volatile and come through peaks that quickly drop\u00a0off.</p>\n<h3>Reading</h3>\n<p>A primary goal of mine in the last few years has been to make it a habit of reading. I would like to dive into my reading habits, understand where I am currently falling short, and what actions I could take to improve this habit. A major value of digitising your inputs is that certain apps will track your behaviour and allow you to export that data. Amazon Kindle insights track your reading habits over time. This section will introduce predictive analytics, and how we can use the synergistic effects of our data to drive future behavior.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*aO8jV3FWeHPdqlLiwlkwig.png\"><figcaption>Visualization of my reading\u00a0habits</figcaption></figure><p>Once again a seasonal pattern seems to be at foot in which I am less likely to stick to my habits over the summer months, as I may be prioritizing fun, and outdoor activities (As you\u00a0should).</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*f1ap-hquX-cDWb63pT50yw.png\"><figcaption>A 30-day moving average of days\u00a0read</figcaption></figure><p>By taking a proportion of days read in the last 30 days, this seasonal pattern can be better identified. This is a very good example of exposing a behavioural pattern of\u00a0mine.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*VgkgNiku5kPqFFgvyotvQQ.png\"><figcaption>Daily Reading\u00a0habits</figcaption></figure><p>Additionally, we can see that on Fridays, Saturdays and Sundays I would be much less likely to read. This implies that to increase my frequency of reading I should focus on finding a 20-minute slot over the weekends to read, leading to the highest return in improving this\u00a0habit.</p>\n<h4>Impact of journaling on reading\u00a0habit</h4>\n<p>This is the first example of how storing two disparate datasets embodies network effects, as my reading habits and journaling habits can be leveraged together to identify behavioural patterns not visible through analysis in isolation.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*tpa-8KE_--Yf5vH3lU_Hyg.png\"><figcaption>Reading habits and journaling</figcaption></figure><p>Days in which I journaled have a much higher likelihood of me reading. Journaling is usually the first thing I do when I wake up and implies there is a pattern of habit continuity in that I am more likely to follow through with other habits if I perform the first one of the\u00a0day.</p>\n<h4>Predicting my likelihood of\u00a0reading</h4>\n<p>Let\u2019s take this a step further, and try and predict the probability that I will read in a given day based on historical trends in the data. This introduces us to the concept of predictive analytics and determining my future behaviour based on other\u00a0habits.</p>\n<p>One hot encoding the months and days of the week, as well as adding a binary feature journaled (True, if I journaled that day) and the lagged moving average of the proportion of days reading in the last 2 weeks. I can perform a simple regression analysis, determining the impact of previous behaviours and seasonal/weekly trends.</p>\n<p>My training set consists of the first 408 days between October 1st 2022 and November 11th 2023. My test set consists of 100 days from November 11th up until the 2nd of February\u00a02024.</p>\n<pre>              precision    recall  f1-score   support<br><br>         0.0       0.57      0.27      0.36        15<br>         1.0       0.88      0.96      0.92        85<br><br>    accuracy                           0.86       100<br>   macro avg       0.73      0.62      0.64       100<br>weighted avg       0.84      0.86      0.84       100<br><br>journalled: 1.1440068424395116<br>month_1: 0.16044342220670138<br>month_2: 0.3323670002244325<br>month_3: 0.7024553142987882<br>month_4: 0.22966851950692688<br>month_5: -0.8973105152837405<br>month_6: -0.30571280967693937<br>month_7: -0.26748064587381354<br>month_8: -0.3400904017551615<br>month_9: -0.47128785358425396<br>month_10: 1.1122827221321216<br>month_11: -0.11306428172788532<br>month_12: -0.1512587216823901<br>day_0: 0.21844147183274587<br>day_1: 0.5648366645343597<br>day_2: 0.40001927074086285<br>day_3: 0.5277073233344185<br>day_4: -0.5166125876634535<br>day_5: -1.2279971272203802<br>day_6: 0.0246167332262347<br>lagged_moving_average: 1.2349710812455899<br>Prediction for the last day (Feb 21, 2024): Read</pre>\n<p>The model excels at predicting the day when I will read, with a precision of 88%. However, predicting days I will not read is less evident with a much weaker precision of\u00a057%.</p>\n<p><strong>Findings</strong></p>\n<ul>\n<li>Journaling is clearly shown to increase my likelihood of reading, as indicated by a positive coefficient of\u00a01.144</li>\n<li>A seasonal trend is identified as summer months negatively impact the probability of\u00a0reading</li>\n<li>A weekly trend is also identified with negative coefficients for Fridays and Saturdays</li>\n<li>Consistency of behaviour is identified as I am more likely to read in a given day if I have been reading a lot in the last 2\u00a0weeks</li>\n</ul>\n<p><strong>Predicting future behaviour</strong></p>\n<p>The model predicts that on Wednesday, February 21st 2024, a day in which I journaled my lagged 14-day moving average of the proportion of days read is 0.93%. I have a 92.5% probability of reading that\u00a0day.</p>\n<h3>Prescriptive Analytics</h3>\n<p>Finally, onto the holy grail of analytics. Prescriptive analytics. Imagine a system in which you can capture and automate routine processes. Have a specialist trained on your data and suggest to you actions to take based on your previous behaviour or concerns you have addressed. Or simply a system that can explain to you any concept you have ever faced in your own words. Well, that is the subject of part three of this blog, which dives into how to use the RAG architecture and GPT agents to leverage your data in scaling your abilities and reduce the burden of administrative work in your day-to-day life.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b4f8e5cc8caf\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["nlp","knowledge-management","visualization","machine-learning"]},{"title":"A Data-Driven Productivity System","pubDate":"2024-02-22 11:34:15","link":"https://medium.com/@alexgirardet/a-data-driven-productivity-system-b28379dcf328?source=rss-c365d560a735------2","guid":"https://medium.com/p/b28379dcf328","author":"Alexgirardet","thumbnail":"","description":"\n<p>Becoming Data Driven, and leveraging the analytical use cases that drive Unicorn Startups\u00a0today.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*wf69txynUphwf7AGS-wlsw.jpeg\"></figure><h3>Data: A Competitive Advantage</h3>\n<p>Other than brilliant business models and a highly creative motivated workforce, companies like Google, Amazon, Netflix and Tencent share a fundamental mechanism that drives their staggering success. They are <strong>data-driven</strong>. It can be argued that a business\u2019s success is entirely determined by the quality and velocity of decisions it makes daily. Which product feature to release? which market to break into? what is our hiring process? how to price this product? Decisions like these are made every day across the corporate hierarchy, and by optimising the quality of these decisions, these companies have managed to break away from the competition and dominate their industries.</p>\n<p>Across my journey in Data, I have often wondered how could I become data-driven. At the end of the day, the quality of our lives is decided by the quality of our decisions over time. What career should I pursue? Which habits should I pick up? Should I move? Which goals should I set? Like it or not these decisions fundamentally determine the direction and quality of our life. We are entirely accountable for our own decisions, therefore we ought to optimise the quality of the decisions we make every\u00a0day.</p>\n<p>Being data-driven has traditionally been a luxury that only large companies could afford through their leveraging of sophisticated algorithms. Advances in NLP research and platforms democratising open-source AI models like Hugging Face have significantly reduced the barriers for individuals to leverage the same models that drive Unicorn companies across the\u00a0world.</p>\n<p>Throughout this three-part blog series, I will run through the benefits of creating a digital second brain and how I have personally leveraged open-source models to generate insights about my life and improve the quality of my decisions.</p>\n<h3>You as a\u00a0system</h3>\n<p>In the pursuit of becoming data-driven, it\u2019s crucial to understand how we operate as individuals, interact with our environment and how we make decisions. Similarly to how a company will break down their operating model into a high-level architecture, we must understand the mechanisms in place that drive our will to change and make decisions.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*uwDO11AgO1ssVns9O9QLoA.png\"><figcaption>An individual\u2019s Operating Architecture</figcaption></figure><p>This diagram represents my best shot at visualizing this architecture. A few assumptions have been\u00a0made.</p>\n<ol>\n<li>The world is complex, meaning there are 1st, 2nd and 3rd-order consequences of your decisions that are hard to predict or understand.</li>\n<li>Our perspective (filter) determines which information we extract from the complex\u00a0world.</li>\n<li>This filter drives the development of our knowledge which in turn defines our filter. e.g. If you learn more about Computer science your filter will adapt to find information that more seamlessly relates to these newly found concepts.</li>\n<li>Your daily processes and actions utilise your knowledge, and culminate in your\u00a0output.</li>\n<li>Your output can influence your immediate environment.</li>\n<li>You are the sum of your outputs and decisions.</li>\n<li>Who you want to be (Ideal self / Goals) enables a mechanism in which we can identify discrepancies between our goals and outcomes. Which drives the decisions we\u00a0make.</li>\n<li>Finally, who you want to be, also defines your filter as you seek information from the world that will drive you closer to your\u00a0goals.</li>\n</ol>\n<p>An undeniable truth reflected in this diagram is that our actions and outputs significantly influence our surroundings, and our surroundings determine our inputs. My interpretation of this architecture is that if we can digitise our inputs and outputs and meticulously document the nuances of our immediate environment, we can unlock several transformative possibilities. Once again, this mechanism is analogous to a business capturing the decisions they make, such as a product feature release, capturing the inputs from their surroundings, such as user interaction with the product, and then measuring the quality of this decision through the impact it had on a desired outcome (Higher user interaction).</p>\n<h3>Building a Second\u00a0Brain</h3>\n<p>Companies capture information from their environments through SaaS software, the production databases of their products, or purchasing third-party datasets. The average individual will not have these at their disposal. This leads us to develop our digital\u00a0system.</p>\n<p>In Tiago Forte\u2019s \u201cBuilding a Second Brain,\u201d he introduces the idea of constructing a digital repository for the daily barrage of information. Throughout the book, a few key concepts are introduced that our system will leverage.</p>\n<h4>Digitization</h4>\n<p>Digitalization offers a sustainable solution for preserving knowledge, facilitating seamless information transfer with minimal friction. We must aim to digitise all our\u00a0inputs.</p>\n<h4>Network Effect of Information</h4>\n<p>Information, much like the elements of a complex network, gains in value when interconnected with other data points. This principle, known as the <a href=\"https://www.semanticscholar.org/paper/Measuring-the-Value-Of-Information-An-Asset-Moody-Walsh/bc8ee8f7e8509db17e85f8108d41ef3bed5f13cc\">network effect of information</a>, suggests that an intelligently curated digital archive\u200a\u2014\u200aenriched with personal insights and tailored to individual interests\u200a\u2014\u200acan yield exponential benefits over time. In other words, the more inputs from disparate information sources, the higher the value your system has, as unique insights can be generated by the synergistic effects of your\u00a0data.</p>\n<h3>Capture &amp;\u00a0Store</h3>\n<p>The foundation lies in efficiently capturing and storing data. This involves identifying various information sources encountered daily and selecting the appropriate tools for their acquisition and consolidation into a centralized repository. I utilize Notion and Obsidian, each serving distinct purposes: Notion for structured notes and project management and Obsidian for dynamic knowledge storage. Notion serves as my <strong>data lake</strong> in which I aggregate all information about my tasks, book highlights, article highlights and off-the-cuff notes.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qsHJTKShXmBbfRsR38bFkA.png\"><figcaption>Information sources</figcaption></figure><p>Notion offers an API which seamlessly integrates with other services such as Readwise and Zapier. Facilitating the process of creating data pipelines to aggregate your information.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YXFzehtwWHl7hx4g2Unzeg.png\"><figcaption>Readwise highlights integrated with\u00a0Notion</figcaption></figure><h3>Organize</h3>\n<p>Given the diverse nature of information, it necessitates tailored data structures for optimal storage and retrieval.</p>\n<h4>Structured Hierarchical Data</h4>\n<p>This format suits information with inherent hierarchy, such as book highlights, articles, and task-related data. For instance, a highlight from a book is nested within that specific book, which falls under a broader category. Similarly, tasks are organized within projects, aligning with objectives or key performance indicators. <a href=\"https://fortelabs.com/blog/para/\">The PARA system</a> and Agile methodology play a crucial role here, offering a robust framework for organizing tasks and projects.</p>\n<h4>Graph Data</h4>\n<p>For information that defies linear categorization\u200a\u2014\u200alike concepts, facts, and insights\u200a\u2014\u200aI turn to the Zettelkasten system. This approach allows for the creation of interconnected notes, forming a rich web of ideas. Inspired by the work of <a href=\"https://reasonabledeviations.com/2022/04/18/molecular-notes-part-1/\">Robert Andrew Martin</a>, my Obsidian setup thrives on this model, especially effective in mapping the complex relationships between abstract concepts.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qvXqQVZHMpQkbHzLzDxDAw.png\"></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GpcgQxRtZ6r_A06SkmSySA.png\"><figcaption>My concept network and local\u00a0network</figcaption></figure><h3>Distill</h3>\n<p>The distillation phase is where raw information is refined into valuable knowledge assets. Initially captured notes, often in their nascent form, undergo a process of review and synthesis. This stage is pivotal for transforming scattered insights into coherent, actionable knowledge, revealing the depth and utility of the information gathered. Obsidian through its interconnected functionality allows for a seamless distillation process as we can distill conceptual information by relating it to other concepts across the concept network. <em>A concept is fundamentally more understood when related to other concepts.</em></p>\n<a href=\"https://medium.com/media/d1315c58c31612ac98589859209723f7/href\">https://medium.com/media/d1315c58c31612ac98589859209723f7/href</a><h3>Express</h3>\n<p>Expression is the stage in which refined ideas are articulated and shared. This stage is particularly enlightening, as it often reveals the gaps in our understanding, pushing us to deepen our insights. For me, articulating thoughts, whether through writing or other mediums, not only consolidates my learning but also invites feedback and new perspectives. So far, blogging is my attempt to do so. However, Notion and Obsidian incentivise knowledge sharing through online\u00a0links.</p>\n<h3>Leveraging AI</h3>\n<p>My system has been developed over the last 18 months and continues to be refined every day. However, I currently feel confident that I have aggregated enough data to leverage AI and other statistical techniques to generate insights into my life. Parts 2 and 3 will dive into how I leverage the three subsets of analytics to gain a competitive advantage from my\u00a0data.</p>\n<h4>Descriptive analytics</h4>\n<ul>\n<li>\n<strong>Purpose</strong>: To summarize past data and understand what has happened.</li>\n<li>Blog: Part\u00a02</li>\n</ul>\n<h4>Predictive Analytics</h4>\n<ul>\n<li>\n<strong>Purpose</strong>: To forecast future outcomes based on historical data.</li>\n<li>Blog: Part\u00a02</li>\n</ul>\n<h4>Prescriptive Analytics</h4>\n<ul>\n<li>\n<strong>Purpose</strong>: To recommend actions you can take to affect desired outcomes.</li>\n<li>Blog: Part\u00a03.</li>\n</ul>\n<h4>My system summary statistics</h4>\n<ul>\n<li>Notion Notes:\u00a0557</li>\n<li>Notion Tasks:\u00a0278</li>\n<li>Notion projects: 38</li>\n<li>Books: 87</li>\n<li>Articles: 58</li>\n<li>Obsidian notes:\u00a0212</li>\n</ul>\n<h3>Resources</h3>\n<ul>\n<li>Robert Andrew Martin\u2019s blog: <a href=\"https://reasonabledeviations.com/2022/04/18/molecular-notes-part-1/\">https://reasonabledeviations.com/2022/04/18/molecular-notes-part-1/</a>\n</li>\n<li>Tiago Forte\u2019s: Building a Second\u00a0Brain</li>\n<li>Thomas Frank\u2019s YouTube Channel: <a href=\"https://www.youtube.com/watch?v=vs8WQh2k-Ow\">https://www.youtube.com/watch?v=vs8WQh2k-Ow</a>\n</li>\n<li>James Clear\u2019s: Atomic\u00a0Habits</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b28379dcf328\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>Becoming Data Driven, and leveraging the analytical use cases that drive Unicorn Startups\u00a0today.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*wf69txynUphwf7AGS-wlsw.jpeg\"></figure><h3>Data: A Competitive Advantage</h3>\n<p>Other than brilliant business models and a highly creative motivated workforce, companies like Google, Amazon, Netflix and Tencent share a fundamental mechanism that drives their staggering success. They are <strong>data-driven</strong>. It can be argued that a business\u2019s success is entirely determined by the quality and velocity of decisions it makes daily. Which product feature to release? which market to break into? what is our hiring process? how to price this product? Decisions like these are made every day across the corporate hierarchy, and by optimising the quality of these decisions, these companies have managed to break away from the competition and dominate their industries.</p>\n<p>Across my journey in Data, I have often wondered how could I become data-driven. At the end of the day, the quality of our lives is decided by the quality of our decisions over time. What career should I pursue? Which habits should I pick up? Should I move? Which goals should I set? Like it or not these decisions fundamentally determine the direction and quality of our life. We are entirely accountable for our own decisions, therefore we ought to optimise the quality of the decisions we make every\u00a0day.</p>\n<p>Being data-driven has traditionally been a luxury that only large companies could afford through their leveraging of sophisticated algorithms. Advances in NLP research and platforms democratising open-source AI models like Hugging Face have significantly reduced the barriers for individuals to leverage the same models that drive Unicorn companies across the\u00a0world.</p>\n<p>Throughout this three-part blog series, I will run through the benefits of creating a digital second brain and how I have personally leveraged open-source models to generate insights about my life and improve the quality of my decisions.</p>\n<h3>You as a\u00a0system</h3>\n<p>In the pursuit of becoming data-driven, it\u2019s crucial to understand how we operate as individuals, interact with our environment and how we make decisions. Similarly to how a company will break down their operating model into a high-level architecture, we must understand the mechanisms in place that drive our will to change and make decisions.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*uwDO11AgO1ssVns9O9QLoA.png\"><figcaption>An individual\u2019s Operating Architecture</figcaption></figure><p>This diagram represents my best shot at visualizing this architecture. A few assumptions have been\u00a0made.</p>\n<ol>\n<li>The world is complex, meaning there are 1st, 2nd and 3rd-order consequences of your decisions that are hard to predict or understand.</li>\n<li>Our perspective (filter) determines which information we extract from the complex\u00a0world.</li>\n<li>This filter drives the development of our knowledge which in turn defines our filter. e.g. If you learn more about Computer science your filter will adapt to find information that more seamlessly relates to these newly found concepts.</li>\n<li>Your daily processes and actions utilise your knowledge, and culminate in your\u00a0output.</li>\n<li>Your output can influence your immediate environment.</li>\n<li>You are the sum of your outputs and decisions.</li>\n<li>Who you want to be (Ideal self / Goals) enables a mechanism in which we can identify discrepancies between our goals and outcomes. Which drives the decisions we\u00a0make.</li>\n<li>Finally, who you want to be, also defines your filter as you seek information from the world that will drive you closer to your\u00a0goals.</li>\n</ol>\n<p>An undeniable truth reflected in this diagram is that our actions and outputs significantly influence our surroundings, and our surroundings determine our inputs. My interpretation of this architecture is that if we can digitise our inputs and outputs and meticulously document the nuances of our immediate environment, we can unlock several transformative possibilities. Once again, this mechanism is analogous to a business capturing the decisions they make, such as a product feature release, capturing the inputs from their surroundings, such as user interaction with the product, and then measuring the quality of this decision through the impact it had on a desired outcome (Higher user interaction).</p>\n<h3>Building a Second\u00a0Brain</h3>\n<p>Companies capture information from their environments through SaaS software, the production databases of their products, or purchasing third-party datasets. The average individual will not have these at their disposal. This leads us to develop our digital\u00a0system.</p>\n<p>In Tiago Forte\u2019s \u201cBuilding a Second Brain,\u201d he introduces the idea of constructing a digital repository for the daily barrage of information. Throughout the book, a few key concepts are introduced that our system will leverage.</p>\n<h4>Digitization</h4>\n<p>Digitalization offers a sustainable solution for preserving knowledge, facilitating seamless information transfer with minimal friction. We must aim to digitise all our\u00a0inputs.</p>\n<h4>Network Effect of Information</h4>\n<p>Information, much like the elements of a complex network, gains in value when interconnected with other data points. This principle, known as the <a href=\"https://www.semanticscholar.org/paper/Measuring-the-Value-Of-Information-An-Asset-Moody-Walsh/bc8ee8f7e8509db17e85f8108d41ef3bed5f13cc\">network effect of information</a>, suggests that an intelligently curated digital archive\u200a\u2014\u200aenriched with personal insights and tailored to individual interests\u200a\u2014\u200acan yield exponential benefits over time. In other words, the more inputs from disparate information sources, the higher the value your system has, as unique insights can be generated by the synergistic effects of your\u00a0data.</p>\n<h3>Capture &amp;\u00a0Store</h3>\n<p>The foundation lies in efficiently capturing and storing data. This involves identifying various information sources encountered daily and selecting the appropriate tools for their acquisition and consolidation into a centralized repository. I utilize Notion and Obsidian, each serving distinct purposes: Notion for structured notes and project management and Obsidian for dynamic knowledge storage. Notion serves as my <strong>data lake</strong> in which I aggregate all information about my tasks, book highlights, article highlights and off-the-cuff notes.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qsHJTKShXmBbfRsR38bFkA.png\"><figcaption>Information sources</figcaption></figure><p>Notion offers an API which seamlessly integrates with other services such as Readwise and Zapier. Facilitating the process of creating data pipelines to aggregate your information.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YXFzehtwWHl7hx4g2Unzeg.png\"><figcaption>Readwise highlights integrated with\u00a0Notion</figcaption></figure><h3>Organize</h3>\n<p>Given the diverse nature of information, it necessitates tailored data structures for optimal storage and retrieval.</p>\n<h4>Structured Hierarchical Data</h4>\n<p>This format suits information with inherent hierarchy, such as book highlights, articles, and task-related data. For instance, a highlight from a book is nested within that specific book, which falls under a broader category. Similarly, tasks are organized within projects, aligning with objectives or key performance indicators. <a href=\"https://fortelabs.com/blog/para/\">The PARA system</a> and Agile methodology play a crucial role here, offering a robust framework for organizing tasks and projects.</p>\n<h4>Graph Data</h4>\n<p>For information that defies linear categorization\u200a\u2014\u200alike concepts, facts, and insights\u200a\u2014\u200aI turn to the Zettelkasten system. This approach allows for the creation of interconnected notes, forming a rich web of ideas. Inspired by the work of <a href=\"https://reasonabledeviations.com/2022/04/18/molecular-notes-part-1/\">Robert Andrew Martin</a>, my Obsidian setup thrives on this model, especially effective in mapping the complex relationships between abstract concepts.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*qvXqQVZHMpQkbHzLzDxDAw.png\"></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GpcgQxRtZ6r_A06SkmSySA.png\"><figcaption>My concept network and local\u00a0network</figcaption></figure><h3>Distill</h3>\n<p>The distillation phase is where raw information is refined into valuable knowledge assets. Initially captured notes, often in their nascent form, undergo a process of review and synthesis. This stage is pivotal for transforming scattered insights into coherent, actionable knowledge, revealing the depth and utility of the information gathered. Obsidian through its interconnected functionality allows for a seamless distillation process as we can distill conceptual information by relating it to other concepts across the concept network. <em>A concept is fundamentally more understood when related to other concepts.</em></p>\n<a href=\"https://medium.com/media/d1315c58c31612ac98589859209723f7/href\">https://medium.com/media/d1315c58c31612ac98589859209723f7/href</a><h3>Express</h3>\n<p>Expression is the stage in which refined ideas are articulated and shared. This stage is particularly enlightening, as it often reveals the gaps in our understanding, pushing us to deepen our insights. For me, articulating thoughts, whether through writing or other mediums, not only consolidates my learning but also invites feedback and new perspectives. So far, blogging is my attempt to do so. However, Notion and Obsidian incentivise knowledge sharing through online\u00a0links.</p>\n<h3>Leveraging AI</h3>\n<p>My system has been developed over the last 18 months and continues to be refined every day. However, I currently feel confident that I have aggregated enough data to leverage AI and other statistical techniques to generate insights into my life. Parts 2 and 3 will dive into how I leverage the three subsets of analytics to gain a competitive advantage from my\u00a0data.</p>\n<h4>Descriptive analytics</h4>\n<ul>\n<li>\n<strong>Purpose</strong>: To summarize past data and understand what has happened.</li>\n<li>Blog: Part\u00a02</li>\n</ul>\n<h4>Predictive Analytics</h4>\n<ul>\n<li>\n<strong>Purpose</strong>: To forecast future outcomes based on historical data.</li>\n<li>Blog: Part\u00a02</li>\n</ul>\n<h4>Prescriptive Analytics</h4>\n<ul>\n<li>\n<strong>Purpose</strong>: To recommend actions you can take to affect desired outcomes.</li>\n<li>Blog: Part\u00a03.</li>\n</ul>\n<h4>My system summary statistics</h4>\n<ul>\n<li>Notion Notes:\u00a0557</li>\n<li>Notion Tasks:\u00a0278</li>\n<li>Notion projects: 38</li>\n<li>Books: 87</li>\n<li>Articles: 58</li>\n<li>Obsidian notes:\u00a0212</li>\n</ul>\n<h3>Resources</h3>\n<ul>\n<li>Robert Andrew Martin\u2019s blog: <a href=\"https://reasonabledeviations.com/2022/04/18/molecular-notes-part-1/\">https://reasonabledeviations.com/2022/04/18/molecular-notes-part-1/</a>\n</li>\n<li>Tiago Forte\u2019s: Building a Second\u00a0Brain</li>\n<li>Thomas Frank\u2019s YouTube Channel: <a href=\"https://www.youtube.com/watch?v=vs8WQh2k-Ow\">https://www.youtube.com/watch?v=vs8WQh2k-Ow</a>\n</li>\n<li>James Clear\u2019s: Atomic\u00a0Habits</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b28379dcf328\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["data-science","data-driven","productivity","notion","ai"]},{"title":"Unravelling Complexity: How nature, systems and cognition shape human learning","pubDate":"2024-01-21 11:16:51","link":"https://medium.com/@alexgirardet/unravelling-complexity-how-nature-systems-and-cognition-shape-human-learning-58e4c829d46f?source=rss-c365d560a735------2","guid":"https://medium.com/p/58e4c829d46f","author":"Alexgirardet","thumbnail":"","description":"\n<p>Humanity has achieved incredible feats, from exploring the depths of space to developing vaccines that counter once-fatal diseases. We\u2019ve extracted natural resources to build breathtaking skylines, a testament to our collective intelligence. I am constantly in awe of these achievements, which continue to grow in scale and impact. As we enter an exciting period in history, leveraging Artificial Intelligence, developing renewable energy sources, and advancing genetic editing, it prompts reflection. How did we get here? In answering this, we explore how nature\u2019s complexity, intertwined systems, and cognitive evolution have shaped the way we learn and interact with the world, allowing us to overcome the obstacles in our\u00a0path.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*Oa7eDv1Ic0ZdVPYu0RKhjw.png\"><figcaption>Singapore Skyline</figcaption></figure><h3>Look to nature to understand reality</h3>\n<p>Despite mankind\u2019s remarkable intelligence relative to other species; many complex phenomena lie beyond our ability to understand or replicate. Even our most skilled experts are incapable of designing an organism as intricate as a human or a dog. Such complexity remains in the domain of nature. This observation leads to the premise that nature, through its evolutionary mechanisms and the passage of time, possesses a remarkable capacity for generating complexity and fostering highly adaptive organisms.</p>\n<p>The assumption of nature as the greatest force of intelligence is an acknowledgement of the efficiency and effectiveness of natural processes in creating complex and adaptive systems. The development of these systems is driven by two fundamental mechanisms: <strong>evolution</strong> and <strong>natural selection</strong>. Over many generations, these processes allow for the gradual development of incredibly complex and intricate organisms that are well-adapted to their environments. Nature did not have a conscious goal in creating these entities, they were a consequence of reproductive and survival success over many millennia.</p>\n<p>Over the last million years of evolution, human brains have grown larger and more complex, resulting in increased cognitive capabilities, and the ability to process large amounts of information. Additionally, the human brain takes up 20% of our energy consumption. Again, this was not by mistake but by design. With energy sources being so scarce in the environment where our ancestors lived. It\u2019s worth asking why nature deemed brain power and therefore our ability to learn and reason as so paramount to our survival that it deserved 1/5 of our energy despite making up 2% of our total weight. To answer this I look to systems and the complexity within\u00a0them.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/850/1*PHhNFLFgkGmTvw9rHfzeuA.png\"><figcaption>Brain volume increase over millions of\u00a0years</figcaption></figure><h3>System theory</h3>\n<p>Systems theory is a way of viewing the world through the lens of systems, where most things are part of interconnected systems, working together and influencing each other. This view lies on the principle that the parts of a system can be best understood in the context of the relationships with each other and other systems, rather than in isolation. Staying true to this principle, we must understand how humans can be viewed as systems, and our interactions with our environment as a larger encompassing system. This provides insights into why our brain has developed in this\u00a0fashion.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/850/1*CG5eA54ILYLYHK36NPWG6A.png\"><figcaption>A high-level view of a\u00a0system</figcaption></figure><p>A system is an interconnected set of elements that is coherently organised in a way that achieves something. Put simply, they must be made up of three things: elements, interconnections, and a function or purpose. For example, the elements of a human include our heart, brain, lungs and muscles that work together and make us function as a whole. Each element has a specific function. The heart pumps blood throughout the body. The brain processes information from the senses. The lungs are responsible for breathing. Muscles enable movement.</p>\n<p>The overall purpose of the system is to sustain life and enable the various activities that allow humans to survive in their environment. The elements of the human system are highly interconnected and interdependent. These elements work together through information channels such as the circulatory system or nervous\u00a0system.</p>\n<h4>Complexity</h4>\n<p>A system can be extremely complex. Complexity refers to the quality of a system that has multiple interrelated components, each influencing and interacting with each other in dynamic ways. Usually, these interactions are non-linear and the dynamic behavior of complex systems means that relationships between elements can change over time. Another component of complex systems is feedback loops. The output of a system can impact its input through a positive or negative feedback mechanism, dampening or enhancing the overall behaviour of the\u00a0system.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/586/1*uxE76CEdCSWYLj5w1IUxdw.png\"><figcaption>Relationships within a system leading to complexity</figcaption></figure><p>A great example of radical behaviour change within a system is the Indian population system. Initially, high mortality rates due to limited access to healthcare acted as a negative feedback loop preventing large population increases. Following Indian Independence in 1947, vaccines and antibiotics were introduced, reducing the impact of diseases such as Smallpox and Tuberculosis. The resulting decrease in mortality rate enabled a positive feedback loop. An increase in population led to more births, further increasing the population. The shift from negative to positive feedback loops led to exponential growth. This example illustrates how a change in a single component of a system (Mortality rate) can propagate, and lead to drastic changes in overall behaviour. The butterfly effect aims to illustrate this point using an extreme example. A single butterfly wing flap in Brazil could propagate through our weather system and eventually act as the catalyst for a tornado in Kentucky.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*Z5NnFL1DTmQW6KAvgQ-xTw.jpeg\"><figcaption>Drastic change in the Indian population system</figcaption></figure><h4>Emergent properties</h4>\n<p>Finally, complex systems can have emergent properties. These are new characteristics or behaviours that arise from the interactions within a system that cannot be predicted by analysing its components. These properties are the result of complex interdependencies and interactions, making it hard to foresee how they will manifest. My favourite example of emergent properties is the formation of shapes by flocks of birds in flight. The seemingly random, yet coordinated patterns that emerge as the birds fly together are not directed by any single bird but arise from the interactions of individual birds following simple rules. Predicting the future formation of these shapes would be extremely challenging and is generally not possible with high precision.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/480/1*5MJF4hK8whwd9pMUk1j6mQ.gif\"><figcaption>A system of birds with emergent properties</figcaption></figure><p>To survive within the unpredictable natural domain, humans needed to develop mechanisms to reason and make decisions in light of overwhelming complexity. We needed to understand where and how to acquire resources, how to avoid hazards and predators, and how to adapt to changing conditions. We needed a means to make sense of complex information and distil it into more manageable and understandable forms. Importantly, humans are limited by biological constraints. There is only so much energy our brains can consume in processing the world around us. Therefore we naturally evolved mechanisms to better identify patterns in our environment and created cognitive processes that helped us avoid being overwhelmed by the vast amount of information in complex\u00a0systems.</p>\n<h3>Cognitive processes</h3>\n<p>A cognitive process is a mental activity involved in acquiring, processing, storing and applying information. These processes are fundamental in our ability to perceive, reason, remember, and learn. Cognitive processes enable us to interpret and interact with the world around us. The three primary cognitive processes involved in learning, are abstraction, conceptualisation and generalisation.</p>\n<h4>Abstraction</h4>\n<p><strong>Abstraction</strong> helps us simplify complex entities by focusing on their essential qualities and ignoring less relevant details. Take a church as an example. Thinking of a church, you probably imagine a basic shape with a spire and a rectangular base, rather than a specific church you\u2019ve seen. Given our limited cognitive resources, your brain does not have the memory capacity to save the exact image of every church you have seen. However, a mechanism is needed to identify one. Over time, your brain extracts the essential features, and characteristic patterns from the churches you have encountered and creates a model that can be quickly applied in determining if an object is a church. If the object is similar enough to your model, it will be deemed to be a church. This process is called abstraction, and through it, you have developed a <strong>mental\u00a0model</strong>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/850/1*XLNwLlAVGpb4xPsBPoCz8A.png\"><figcaption>Abstraction process of a\u00a0church</figcaption></figure><h3>Conceptualization</h3>\n<p>Armed with a new mental model. You may aim to leverage it in your day-to-day life. But what if we had seen other similar objects in the past? How can we leverage our pre-existing knowledge to better understand a new concept that we are faced with? This is achieved through C<strong>onceptualisation</strong>. The difference between Conceptualization and Abstraction is subtle but significant. Both involve forming a detailed mental model of an abstracted concept, however, Conceptualization includes the added process of understanding the boundaries and relationships of this new concept within the context of other previously abstracted concepts.</p>\n<p>When you first see a truck, you notice it shares features with cars\u200a\u2014\u200awheels, an engine, and a purpose for transportation. Through conceptualization, you relate this new information to your existing knowledge of vehicles. While both trucks and cars are vehicles, you understand their different purposes: cars for personal transport, and trucks for carrying heavy loads. This helps you form a broader vehicle category in your mind. When encountering a bus, although it\u2019s unfamiliar, you use your conceptual understanding of vehicles to make informed predictions about its purpose and functionality, demonstrating how conceptualization allows you to adapt previous knowledge to new situations.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/904/1*Ft43bTo3rMLevn8hz6J6Ew.png\"><figcaption>Concept Network of\u00a0Vehicles</figcaption></figure><p>Conceptualisation adapts and fits abstract mental models into a <strong>concept network</strong>. A concept network is a network of knowledge within the brain. It is made up of concepts and connections linking them together. Concept networks often have a hierarchical structure, with more general concepts at higher levels and more specific ones at lower levels. This hierarchy helps in organising information in a way that reflects our understanding of the\u00a0world.</p>\n<h3>Generalization</h3>\n<p>Finally, Generalization is a cognitive process through which we apply knowledge, skills, or responses learned in one situation to new, different situations. This ability leverages abstraction and conceptualization and is crucial for adaptive behaviour. Generalization enables us to navigate and understand our ever-changing environment without needing to learn from scratch every time we encounter something new. It allows us to determine if something new is similar enough to existing concepts in our network and then apply our accumulated knowledge and understanding from that network to the new situation.</p>\n<p>For example, if you learn how to ride a bicycle, you can generalize that skill to ride different types of bicycles or even similar vehicles like scooters, without starting from scratch each time. This makes generalization an efficient process, reducing the cognitive load and allowing us to adapt quickly to new scenarios.</p>\n<h3>Conclusion</h3>\n<p>Throughout millions of years, species have engaged with their complex environments, striving for survival and reproduction. Each species has evolved unique mechanisms to achieve these ends. Among these, humanity\u2019s standout survival tool is our capacity for reasoning, learning, and adapting to our surroundings\u200a\u2014\u200aa skillset honed through the process of evolution. By distilling the chaos of our environment into simpler forms through abstraction, and by conceptualizing these patterns in the context of our past experiences, we\u2019ve mastered the art of generalizing ideas and concepts to entirely new situations. This ability underpins our exceptionally adaptive behaviour. As we continue to encounter novel challenges, I am confident that our species will persist in learning from both ourselves and the world around us, discovering innovative solutions to the problems we\u00a0face</p>\n<h3>Resources</h3>\n<ul>\n<li>Book: <strong>How to create a mind</strong> by Ray\u00a0Kurzweil</li>\n<li>Book: <strong>Thinking in Systems</strong> by Donella H.Meadows</li>\n<li>Book: <strong>Complex Adaptive Systems </strong>by John\u00a0H.Miller</li>\n<li>Blog: <a href=\"https://supermemo.guru/wiki/Concept_network\">https://supermemo.guru/wiki/</a> by Dr <a href=\"https://supermemo.guru/wiki/Piotr_Wozniak\">Piotr\u00a0Wozniak</a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=58e4c829d46f\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>Humanity has achieved incredible feats, from exploring the depths of space to developing vaccines that counter once-fatal diseases. We\u2019ve extracted natural resources to build breathtaking skylines, a testament to our collective intelligence. I am constantly in awe of these achievements, which continue to grow in scale and impact. As we enter an exciting period in history, leveraging Artificial Intelligence, developing renewable energy sources, and advancing genetic editing, it prompts reflection. How did we get here? In answering this, we explore how nature\u2019s complexity, intertwined systems, and cognitive evolution have shaped the way we learn and interact with the world, allowing us to overcome the obstacles in our\u00a0path.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*Oa7eDv1Ic0ZdVPYu0RKhjw.png\"><figcaption>Singapore Skyline</figcaption></figure><h3>Look to nature to understand reality</h3>\n<p>Despite mankind\u2019s remarkable intelligence relative to other species; many complex phenomena lie beyond our ability to understand or replicate. Even our most skilled experts are incapable of designing an organism as intricate as a human or a dog. Such complexity remains in the domain of nature. This observation leads to the premise that nature, through its evolutionary mechanisms and the passage of time, possesses a remarkable capacity for generating complexity and fostering highly adaptive organisms.</p>\n<p>The assumption of nature as the greatest force of intelligence is an acknowledgement of the efficiency and effectiveness of natural processes in creating complex and adaptive systems. The development of these systems is driven by two fundamental mechanisms: <strong>evolution</strong> and <strong>natural selection</strong>. Over many generations, these processes allow for the gradual development of incredibly complex and intricate organisms that are well-adapted to their environments. Nature did not have a conscious goal in creating these entities, they were a consequence of reproductive and survival success over many millennia.</p>\n<p>Over the last million years of evolution, human brains have grown larger and more complex, resulting in increased cognitive capabilities, and the ability to process large amounts of information. Additionally, the human brain takes up 20% of our energy consumption. Again, this was not by mistake but by design. With energy sources being so scarce in the environment where our ancestors lived. It\u2019s worth asking why nature deemed brain power and therefore our ability to learn and reason as so paramount to our survival that it deserved 1/5 of our energy despite making up 2% of our total weight. To answer this I look to systems and the complexity within\u00a0them.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/850/1*PHhNFLFgkGmTvw9rHfzeuA.png\"><figcaption>Brain volume increase over millions of\u00a0years</figcaption></figure><h3>System theory</h3>\n<p>Systems theory is a way of viewing the world through the lens of systems, where most things are part of interconnected systems, working together and influencing each other. This view lies on the principle that the parts of a system can be best understood in the context of the relationships with each other and other systems, rather than in isolation. Staying true to this principle, we must understand how humans can be viewed as systems, and our interactions with our environment as a larger encompassing system. This provides insights into why our brain has developed in this\u00a0fashion.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/850/1*CG5eA54ILYLYHK36NPWG6A.png\"><figcaption>A high-level view of a\u00a0system</figcaption></figure><p>A system is an interconnected set of elements that is coherently organised in a way that achieves something. Put simply, they must be made up of three things: elements, interconnections, and a function or purpose. For example, the elements of a human include our heart, brain, lungs and muscles that work together and make us function as a whole. Each element has a specific function. The heart pumps blood throughout the body. The brain processes information from the senses. The lungs are responsible for breathing. Muscles enable movement.</p>\n<p>The overall purpose of the system is to sustain life and enable the various activities that allow humans to survive in their environment. The elements of the human system are highly interconnected and interdependent. These elements work together through information channels such as the circulatory system or nervous\u00a0system.</p>\n<h4>Complexity</h4>\n<p>A system can be extremely complex. Complexity refers to the quality of a system that has multiple interrelated components, each influencing and interacting with each other in dynamic ways. Usually, these interactions are non-linear and the dynamic behavior of complex systems means that relationships between elements can change over time. Another component of complex systems is feedback loops. The output of a system can impact its input through a positive or negative feedback mechanism, dampening or enhancing the overall behaviour of the\u00a0system.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/586/1*uxE76CEdCSWYLj5w1IUxdw.png\"><figcaption>Relationships within a system leading to complexity</figcaption></figure><p>A great example of radical behaviour change within a system is the Indian population system. Initially, high mortality rates due to limited access to healthcare acted as a negative feedback loop preventing large population increases. Following Indian Independence in 1947, vaccines and antibiotics were introduced, reducing the impact of diseases such as Smallpox and Tuberculosis. The resulting decrease in mortality rate enabled a positive feedback loop. An increase in population led to more births, further increasing the population. The shift from negative to positive feedback loops led to exponential growth. This example illustrates how a change in a single component of a system (Mortality rate) can propagate, and lead to drastic changes in overall behaviour. The butterfly effect aims to illustrate this point using an extreme example. A single butterfly wing flap in Brazil could propagate through our weather system and eventually act as the catalyst for a tornado in Kentucky.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1000/1*Z5NnFL1DTmQW6KAvgQ-xTw.jpeg\"><figcaption>Drastic change in the Indian population system</figcaption></figure><h4>Emergent properties</h4>\n<p>Finally, complex systems can have emergent properties. These are new characteristics or behaviours that arise from the interactions within a system that cannot be predicted by analysing its components. These properties are the result of complex interdependencies and interactions, making it hard to foresee how they will manifest. My favourite example of emergent properties is the formation of shapes by flocks of birds in flight. The seemingly random, yet coordinated patterns that emerge as the birds fly together are not directed by any single bird but arise from the interactions of individual birds following simple rules. Predicting the future formation of these shapes would be extremely challenging and is generally not possible with high precision.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/480/1*5MJF4hK8whwd9pMUk1j6mQ.gif\"><figcaption>A system of birds with emergent properties</figcaption></figure><p>To survive within the unpredictable natural domain, humans needed to develop mechanisms to reason and make decisions in light of overwhelming complexity. We needed to understand where and how to acquire resources, how to avoid hazards and predators, and how to adapt to changing conditions. We needed a means to make sense of complex information and distil it into more manageable and understandable forms. Importantly, humans are limited by biological constraints. There is only so much energy our brains can consume in processing the world around us. Therefore we naturally evolved mechanisms to better identify patterns in our environment and created cognitive processes that helped us avoid being overwhelmed by the vast amount of information in complex\u00a0systems.</p>\n<h3>Cognitive processes</h3>\n<p>A cognitive process is a mental activity involved in acquiring, processing, storing and applying information. These processes are fundamental in our ability to perceive, reason, remember, and learn. Cognitive processes enable us to interpret and interact with the world around us. The three primary cognitive processes involved in learning, are abstraction, conceptualisation and generalisation.</p>\n<h4>Abstraction</h4>\n<p><strong>Abstraction</strong> helps us simplify complex entities by focusing on their essential qualities and ignoring less relevant details. Take a church as an example. Thinking of a church, you probably imagine a basic shape with a spire and a rectangular base, rather than a specific church you\u2019ve seen. Given our limited cognitive resources, your brain does not have the memory capacity to save the exact image of every church you have seen. However, a mechanism is needed to identify one. Over time, your brain extracts the essential features, and characteristic patterns from the churches you have encountered and creates a model that can be quickly applied in determining if an object is a church. If the object is similar enough to your model, it will be deemed to be a church. This process is called abstraction, and through it, you have developed a <strong>mental\u00a0model</strong>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/850/1*XLNwLlAVGpb4xPsBPoCz8A.png\"><figcaption>Abstraction process of a\u00a0church</figcaption></figure><h3>Conceptualization</h3>\n<p>Armed with a new mental model. You may aim to leverage it in your day-to-day life. But what if we had seen other similar objects in the past? How can we leverage our pre-existing knowledge to better understand a new concept that we are faced with? This is achieved through C<strong>onceptualisation</strong>. The difference between Conceptualization and Abstraction is subtle but significant. Both involve forming a detailed mental model of an abstracted concept, however, Conceptualization includes the added process of understanding the boundaries and relationships of this new concept within the context of other previously abstracted concepts.</p>\n<p>When you first see a truck, you notice it shares features with cars\u200a\u2014\u200awheels, an engine, and a purpose for transportation. Through conceptualization, you relate this new information to your existing knowledge of vehicles. While both trucks and cars are vehicles, you understand their different purposes: cars for personal transport, and trucks for carrying heavy loads. This helps you form a broader vehicle category in your mind. When encountering a bus, although it\u2019s unfamiliar, you use your conceptual understanding of vehicles to make informed predictions about its purpose and functionality, demonstrating how conceptualization allows you to adapt previous knowledge to new situations.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/904/1*Ft43bTo3rMLevn8hz6J6Ew.png\"><figcaption>Concept Network of\u00a0Vehicles</figcaption></figure><p>Conceptualisation adapts and fits abstract mental models into a <strong>concept network</strong>. A concept network is a network of knowledge within the brain. It is made up of concepts and connections linking them together. Concept networks often have a hierarchical structure, with more general concepts at higher levels and more specific ones at lower levels. This hierarchy helps in organising information in a way that reflects our understanding of the\u00a0world.</p>\n<h3>Generalization</h3>\n<p>Finally, Generalization is a cognitive process through which we apply knowledge, skills, or responses learned in one situation to new, different situations. This ability leverages abstraction and conceptualization and is crucial for adaptive behaviour. Generalization enables us to navigate and understand our ever-changing environment without needing to learn from scratch every time we encounter something new. It allows us to determine if something new is similar enough to existing concepts in our network and then apply our accumulated knowledge and understanding from that network to the new situation.</p>\n<p>For example, if you learn how to ride a bicycle, you can generalize that skill to ride different types of bicycles or even similar vehicles like scooters, without starting from scratch each time. This makes generalization an efficient process, reducing the cognitive load and allowing us to adapt quickly to new scenarios.</p>\n<h3>Conclusion</h3>\n<p>Throughout millions of years, species have engaged with their complex environments, striving for survival and reproduction. Each species has evolved unique mechanisms to achieve these ends. Among these, humanity\u2019s standout survival tool is our capacity for reasoning, learning, and adapting to our surroundings\u200a\u2014\u200aa skillset honed through the process of evolution. By distilling the chaos of our environment into simpler forms through abstraction, and by conceptualizing these patterns in the context of our past experiences, we\u2019ve mastered the art of generalizing ideas and concepts to entirely new situations. This ability underpins our exceptionally adaptive behaviour. As we continue to encounter novel challenges, I am confident that our species will persist in learning from both ourselves and the world around us, discovering innovative solutions to the problems we\u00a0face</p>\n<h3>Resources</h3>\n<ul>\n<li>Book: <strong>How to create a mind</strong> by Ray\u00a0Kurzweil</li>\n<li>Book: <strong>Thinking in Systems</strong> by Donella H.Meadows</li>\n<li>Book: <strong>Complex Adaptive Systems </strong>by John\u00a0H.Miller</li>\n<li>Blog: <a href=\"https://supermemo.guru/wiki/Concept_network\">https://supermemo.guru/wiki/</a> by Dr <a href=\"https://supermemo.guru/wiki/Piotr_Wozniak\">Piotr\u00a0Wozniak</a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=58e4c829d46f\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["evolution","thinking","systems-thinking","complexity","cognition"]}]}